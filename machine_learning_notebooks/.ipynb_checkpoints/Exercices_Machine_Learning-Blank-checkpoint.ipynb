{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "080071d6-1973-4345-abce-b07237509c8f",
   "metadata": {},
   "source": [
    "##### `Nom et prenom :`\n",
    "##### `Numéro de groupe`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3644a6d4-9c4b-460d-8d64-c1b116f13f5e",
   "metadata": {},
   "source": [
    "# **Résolution de problèmes à l'aide des bibliothèques Scikit learn et Pycaret** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7902dfad-09ba-4baa-ad7e-007344cdc0d9",
   "metadata": {},
   "source": [
    "Ce cahier de notes présente une série d'exercices à résoudre en utilisant les fonctionnalités du package ou de la bibliothèque `pandas`. Chaque exercice doit être résolu à la suite de chaque énoncé, en expliquant de façon claire et concise les étapes utilisées pour y répondre. Les exercices doivent impérativement être résolus à l'aide des fonctions disponibles dans des bibliothèque demandées "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afc9b8d2-8c37-421e-9c38-ea92c4297d0b",
   "metadata": {},
   "source": [
    "### `Exercice 1`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2be9bd2-96b6-49a4-b7dc-71113a0c99b3",
   "metadata": {},
   "source": [
    "Trouvez un jeu de données comportant au moins quatre variables et appliquez-y des techniques de prétraitement telles que l'imputation des valeurs manquantes et l'encodage OneHot. Vous devrez présenter à la fois le DataFrame original et le DataFrame après prétraitement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756f921a-b20d-4401-b6ef-9ce04ea82976",
   "metadata": {},
   "source": [
    "### `Exercice 2`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205e4fdc-295a-44dc-aa03-be195b853c69",
   "metadata": {},
   "source": [
    "Une université américaine souhaite construire un modèle prédictif simple qui lui permette d'anticiper la performance des étudiants en fonction de leurs activités extrascolaires, de leur temps de repos, des heures d'étude, etc. À partir de l'ensemble des données fournies par l'université (`Student_Performance.csv`), répondre aux questions suivantes :\n",
    "\n",
    "- Construire un modèle linéaire  multiple (avec scikitlearn) permettant de prédire la performance des étudiants. Pour ce faire, utilisez la technique de validation croisée avec 5 plis.\n",
    "- Déterminer le RMSE globale à partir des résultats de la validation croisée.\n",
    "- Quelles sont les valeurs des coefficients de régression obtenus ?\n",
    "- Quelles sont les variables les plus influentes sur la performance des étudiants?\n",
    "- Réaliser un graphique représentant les valeurs réelles en abscisse et les valeurs prédites en ordonnée pour l'ensemble de test, puis le superposer au graphique de la droite identité. Quel est le rôle de la droite identité dans ce graphique?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94685330-cf95-4a9a-b8eb-b8e2a0c22e2b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fc6cb4a9-668f-43ee-a861-791046f5161c",
   "metadata": {},
   "source": [
    "### `Exercice 3`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35bbd93-e018-4d63-afe9-146638456587",
   "metadata": {},
   "source": [
    "Avec le même jeu de données de l'exercice précédent, répondre aux questions suivantes :\n",
    "\n",
    "- Trouver la valeur optimale des k plus proches voisins autour des 30 points. Pour ce faire, utiliser la validation croisée avec 5 plis (fold).\n",
    "- Réaliser les graphiques de validation qui représentent l'erreur d'entraînement et l'erreur de validation (prenez comme métrique $r^2$).\n",
    "- Réaliser un graphique représentant les valeurs réelles en ordonnée et les valeurs prédites en abscisse pour l'ensemble de test, puis le superposer au graphique de la droite identité.\n",
    "- L'université vous demande de faire un choix entre le modèle linéaire (exemple précédent) et le modèle des k plus proches voisins. Lequel leur suggéreriez-vous et pour quelles raisons ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f29ccf65-30fd-4545-80b9-9083cae2fbbe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cbea1dd-b043-4036-b911-ba4d6e5a8680",
   "metadata": {},
   "source": [
    "### `Exercice 4`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "242d79e5-28e2-4c73-8517-2e47baf961e7",
   "metadata": {},
   "source": [
    "Un groupe de chercheurs en cancérologie dispose d'une base de données de patients présentant des tumeurs. Ces données contiennent une série de caractéristiques structurales des tumeurs, telles que la taille, la texture, le périmètre, etc. Les chercheurs souhaitent construire un modèle leur permettant de prédire des diagnostics futurs en fonction des caractéristiques de la tumeur. À partir de l'ensemble de données `breast_cancer_winsconsin.csv`, répondez aux questions suivantes:\n",
    "\n",
    "- Réaliser l'entraînement d'un arbre de décision en optimisant la profondeur de l'arbre à l'aide de la validation croisée (k=5) et de l'index de Gini pour la construction de l'arbre. Vous devez également afficher la profondeur maximale optimisée ainsi que l'accuracy obtenue pendant la validation croisée.\n",
    "- Réaliser le graphique de validation qui présente les courbes d'entraînement et de validation pour l'obtention de la profondeur maximale optimisée. Les graphiques doivent être présentés en tant que courbes d'erreur et non en tant que courbes d'accuracy. Réaliser aussi le graphique de votre arbre de décision obtenu\n",
    "- Déterminer sous l'ensemble de test, la précision, le recall et le F1 score:\n",
    "- Combien d'individus ont été mal classé dans l'ensemble de test?\n",
    "- Selon votre modèle, quels sont les paramètres les plus influents pour déterminer le diagnostic?. Réalisez un graphique de barres qui montrera ces paramètres et leur influence sur le diagnostic.\n",
    "- Extrayez la règle de décision de votre modèle et reprogrammez-la en utilisant des règles conditionnelles. Pour ce faire, créez une fonction avec des arguments d'entrée correspondant aux variables définies par la règle de décision.\n",
    "- Comparez les résultats obtenus de votre fonction décisionnelle et ceux obtenus par la fonction `predict` de scikitlearn. Pour ce faire, créez un data frame et détectez s'il y a des incohérences dans les prédictions ou non (!faites attention aux arrondis). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e89e605-1818-43b7-94f6-7fa5612f815c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6f008d6-a801-4e9a-88f0-3914e2a2b874",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed95d0de-979c-4d14-9739-a6541b52be87",
   "metadata": {},
   "source": [
    "### `Exercice 5`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87ce7bcd-bbc9-4071-b64b-481da9b5a927",
   "metadata": {},
   "source": [
    "Plusieurs marques de voitures ont fait appel à une société environnementale canadienne afin qu'elle crée un modèle prédictif permettant d'estimer à l'avance les émissions de gaz à effet de serre (CO₂) produites par leurs véhicules. Ces constructeurs ont fourni à la société un jeu de données présentant des caractéristiques propres aux véhicules : marque, consommation, modèle, type de combustible, etc. En tant que data scientist junior de cette société, on vous demande d'utiliser un modèle de type Random Forest à l'aide de la bibliothèque PyCaret pour résoudre ce problème, en répondant aux questions suivantes:\n",
    "\n",
    "- Entraînez un modèle de type Random Forest. Pour ce faire, suivez les indications suivantes :\n",
    "  - Extrayez les 20 dernières lignes du data frame d'origine et stockez les dans un data frame nommé `data_CO2_emission_pred` pour effectuer des prédictions ultérieurement. Ces lignes doivent être éliminées du data frame sur lequel vous allez entraîner votre modèle. \n",
    "  - Appliquez une normalisation de type centrée réduite aux variables numériques.\n",
    "  - Appliquez un encodage OneHot aux variables qualitatives nominales.\n",
    "  - Utilisez un 5-fold pour optimiser le nombre d'arbres sur un ensemble d'entraînement d'un pourcentage de 70 % de l'échantillon initial.\n",
    "- Traçez le graphique de validation de $r^2$ en fonction du nombre d'estimateur\n",
    "- Quelles sont les caractéristiques les plus déterminantes de l'émission de $CO_2$ des véhicules ?\n",
    "- À partir du modèle optimisé, effectuer les prédictions des données de véhicules dans le data frame `data_CO2_emission_pred`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9694923-6ff7-49c3-921e-3a6e95a743a0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cb685687-6be3-461a-b534-45389d0a7881",
   "metadata": {},
   "source": [
    "### `Exercice 6`\n",
    "Une petite société de marketing souhaite faire une segmentation rapide de ses clients et se demande comment effectuer un clustering kmeans pour obtenir une réponse en temps réel. La société dispose d'un jeu de données `segmentation_data.csv` dont les spécifications de chaque variable se trouvent dans le fichier `segmentation data legend.xlsx`. Vous faites partie de l'équipe et ils vous demandent d'optimiser le nombre de clusters (celui-ci ne doit dépaser de 7) pour cette segmentation. Vous devez répondre aux questions suivantes:\n",
    "\n",
    "- Créez une fonction de normalisation nommée min_max et appliquez-la au DataFrame avant de réaliser la clusterisation\n",
    "- En utilisant la méthode de la silhouette, déterminez le nombre optimal de clusters. Vous devez afficher le graphique permettant d'arriver à ce résultat."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa7431b8-38f2-4bd1-a879-a8aad2f50d10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
